{"cells":[{"cell_type":"code","source":["lakehouse_silverTable = \"abfss://Fabric_E2E@onelake.dfs.fabric.microsoft.com/Lakehouse_Silver_.Lakehouse/Tables\"\n","spark.conf.set(\"spark.executorEnv.lakehouse_silverTable\", lakehouse_silverTable)\n","lakehouse_silver_table = spark.conf.get(\"spark.executorEnv.lakehouse_silverTable\")\n","print(lakehouse_silver_table)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"27a03adf-c6cf-4424-a992-7879b19beb3f","normalized_state":"finished","queued_time":"2025-05-23T19:49:30.3303927Z","session_start_time":"2025-05-23T19:49:30.3314086Z","execution_start_time":"2025-05-23T19:49:39.7603477Z","execution_finish_time":"2025-05-23T19:49:40.1718937Z","parent_msg_id":"e94f126b-3ae9-4f68-a9c6-faaaaee74ad4"},"text/plain":"StatementMeta(, 27a03adf-c6cf-4424-a992-7879b19beb3f, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["abfss://Fabric_E2E@onelake.dfs.fabric.microsoft.com/Lakehouse_Silver_.Lakehouse/Tables\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d851ea67-7f2f-410a-a788-7e863c0e3c6c"},{"cell_type":"code","source":["try:\n","    from pyspark.sql.functions import to_timestamp, date_format, unix_timestamp, row_number, col\n","    from pyspark.sql.window import Window\n","\n","    # Load procedures.csv\n","    proc_df = spark.read.option(\"header\", \"true\").csv(\"Files/raw/procedures.csv\")\n","\n","    # Drop rows missing critical data\n","    proc_df = proc_df.dropna(subset=['PATIENT', 'ENCOUNTER', 'START', 'STOP', 'BASE_COST'])\n","\n","    # Convert timestamps\n","    proc_df = proc_df \\\n","        .withColumn(\"START_TS\", to_timestamp(\"START\", \"yyyy-MM-dd'T'HH:mm:ssX\")) \\\n","        .withColumn(\"STOP_TS\", to_timestamp(\"STOP\", \"yyyy-MM-dd'T'HH:mm:ssX\")) \\\n","        .withColumn(\"DIM_DateId\", date_format(\"START_TS\", \"yyyyMMdd\"))\n","\n","    # Compute procedure duration in minutes\n","    proc_df = proc_df.withColumn(\n","        \"duration_minutes\",\n","        (unix_timestamp(\"STOP_TS\") - unix_timestamp(\"START_TS\")) / 60\n","    )\n","\n","    # Add surrogate key using row_number\n","    windowSpec = Window.orderBy(\"PATIENT\", \"ENCOUNTER\", \"START_TS\")\n","    proc_df = proc_df.withColumn(\"Fact_ProcedureId\", row_number().over(windowSpec))\n","\n","    # Rename and prepare final columns\n","    fact_procedures = proc_df.select(\n","        \"Fact_ProcedureId\",\n","        col(\"ENCOUNTER\").alias(\"DIM_EncounterId\"),\n","        col(\"PATIENT\").alias(\"DIM_patientId\"),\n","        col(\"CODE\").alias(\"DIM_ProcedureCode\"),\n","        col(\"DESCRIPTION\").alias(\"outcome\"),\n","        \"DIM_DateId\",\n","        col(\"BASE_COST\").alias(\"procedure_cost\"),\n","        \"duration_minutes\"\n","    )\n","\n","    # Write to Silver layer\n","    fact_procedures.write \\\n","        .mode(\"overwrite\") \\\n","        .format(\"delta\") \\\n","        .save(f\"{lakehouse_silver_table}/FactProcedures\")\n","\n","except Exception as e:\n","    print(f\"❌ Notebook 'Fact_Procedures' failed: {str(e)} — Skipping to next item in pipeline.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"27a03adf-c6cf-4424-a992-7879b19beb3f","normalized_state":"finished","queued_time":"2025-05-23T19:54:41.9690686Z","session_start_time":null,"execution_start_time":"2025-05-23T19:54:41.9702703Z","execution_finish_time":"2025-05-23T19:54:58.0239905Z","parent_msg_id":"151d76a0-f432-4c55-9d99-2a8ccaeeb788"},"text/plain":"StatementMeta(, 27a03adf-c6cf-4424-a992-7879b19beb3f, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"308d63bc-6a4b-4aa2-b95c-71a179c984cb"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"2aaafc3d-8d61-4a21-99ae-09bb332840ae","known_lakehouses":[{"id":"2aaafc3d-8d61-4a21-99ae-09bb332840ae"}],"default_lakehouse_name":"Lakehouse_E2E","default_lakehouse_workspace_id":"9076d5e4-30ee-441b-8e66-85ac9711a0e2"},"environment":{"environmentId":"31fd62f0-7a25-4de6-8968-114832cf2a84","workspaceId":"9076d5e4-30ee-441b-8e66-85ac9711a0e2"}}},"nbformat":4,"nbformat_minor":5}