{"cells":[{"cell_type":"code","source":["lakehouse_silverTable = \"abfss://Fabric_E2E@onelake.dfs.fabric.microsoft.com/Lakehouse_Silver_.Lakehouse/Tables\"\n","spark.conf.set(\"spark.executorEnv.lakehouse_silverTable\", lakehouse_silverTable)\n","lakehouse_silver_table = spark.conf.get(\"spark.executorEnv.lakehouse_silverTable\")\n","print(lakehouse_silver_table)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"831e43fc-6a27-47f8-90b8-141e0a8fae07","normalized_state":"finished","queued_time":"2025-05-23T21:10:37.0887415Z","session_start_time":"2025-05-23T21:10:37.0896718Z","execution_start_time":"2025-05-23T21:10:48.678046Z","execution_finish_time":"2025-05-23T21:10:49.2546243Z","parent_msg_id":"ff518b74-e2c5-4e10-99e7-9797ec44212e"},"text/plain":"StatementMeta(, 831e43fc-6a27-47f8-90b8-141e0a8fae07, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["abfss://Fabric_E2E@onelake.dfs.fabric.microsoft.com/Lakehouse_Silver_.Lakehouse/Tables\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e360acb0-9eb3-473d-9803-830db6e3f31e"},{"cell_type":"code","source":["try:\n","    from pyspark.sql.functions import to_timestamp, date_format, col, unix_timestamp, row_number, lit\n","    from pyspark.sql.window import Window\n","\n","    # Load encounters.csv\n","    enc_df = spark.read.option(\"header\", \"true\").csv(\"Files/raw/encounters.csv\")\n","\n","    # Drop rows with critical nulls\n","    enc_df = enc_df.dropna(subset=['Id', 'PATIENT', 'START', 'STOP', 'ORGANIZATION'])\n","\n","    # Transform and rename\n","    appt_df = enc_df \\\n","        .withColumnRenamed(\"Id\", \"DIM_EncounterId\") \\\n","        .withColumnRenamed(\"PATIENT\", \"DIM_patientId\") \\\n","        .withColumnRenamed(\"ORGANIZATION\", \"DIM_providerId\") \\\n","        .withColumn(\"START_TS\", to_timestamp(\"START\", \"yyyy-MM-dd'T'HH:mm:ssX\")) \\\n","        .withColumn(\"STOP_TS\", to_timestamp(\"STOP\", \"yyyy-MM-dd'T'HH:mm:ssX\")) \\\n","        .withColumn(\"DIM_DateId\", date_format(col(\"START_TS\"), \"yyyyMMdd\"))\n","\n","    # Calculate duration in minutes\n","    appt_df = appt_df.withColumn(\n","        \"duration_minutes\",\n","        (unix_timestamp(\"STOP_TS\") - unix_timestamp(\"START_TS\")) / 60\n","    )\n","\n","    # Add NULL wait_time (scheduled time not available)\n","    appt_df = appt_df.withColumn(\"wait_time\", lit(None).cast(\"double\"))\n","\n","    # Approximate appointment status\n","    appt_df = appt_df.withColumn(\"status\", col(\"DESCRIPTION\"))\n","\n","    # Use provider as department (fallback)\n","    appt_df = appt_df.withColumn(\"DIM_departmentId\", col(\"DIM_providerId\"))\n","\n","    # Add surrogate key\n","    windowSpec = Window.orderBy(\"DIM_patientId\", \"DIM_DateId\")\n","    appt_df = appt_df.withColumn(\"Fact_AppointmentId\", row_number().over(windowSpec))\n","\n","    raise Exception(\"üí£ Simulated error for testing skip behavior\")\n","\n","\n","    # Final selection\n","    fact_appointments = appt_df.select(\n","        \"Fact_AppointmentId\",\n","        \"DIM_patientId\",\n","        \"DIM_providerId\",\n","        \"DIM_departmentId\",\n","        \"DIM_DateId\",\n","        \"wait_time\",\n","        \"duration_minutes\",\n","        \"status\"\n","    )\n","\n","    # Save to Silver layer\n","    fact_appointments.write \\\n","        .mode(\"overwrite\") \\\n","        .format(\"delta\") \\\n","        .save(f\"{lakehouse_silver_table}/FactAppointments\")\n","\n","except Exception as e:\n","    print(f\"‚ùå Notebook 'Fact_Appointments' failed: {str(e)} ‚Äî Skipping to next item in pipeline.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"831e43fc-6a27-47f8-90b8-141e0a8fae07","normalized_state":"finished","queued_time":"2025-05-23T21:10:37.0956614Z","session_start_time":null,"execution_start_time":"2025-05-23T21:10:49.2567697Z","execution_finish_time":"2025-05-23T21:10:51.792799Z","parent_msg_id":"63b761fe-562f-4cab-9ea0-fc3d4812cda3"},"text/plain":"StatementMeta(, 831e43fc-6a27-47f8-90b8-141e0a8fae07, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚ùå Notebook 'Fact_Appointments' failed: üí£ Simulated error for testing skip behavior ‚Äî Skipping to next item in pipeline.\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"19624c3b-d9a6-40c5-8ac4-5f7a2c6e3521"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"2aaafc3d-8d61-4a21-99ae-09bb332840ae","known_lakehouses":[{"id":"2aaafc3d-8d61-4a21-99ae-09bb332840ae"}],"default_lakehouse_name":"Lakehouse_E2E","default_lakehouse_workspace_id":"9076d5e4-30ee-441b-8e66-85ac9711a0e2"}}},"nbformat":4,"nbformat_minor":5}